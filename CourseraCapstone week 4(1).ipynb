{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applied Data Science Capstone \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction/Business Problem\n",
    "### The scenario: you are an international tourist, you plan to visit Washington D.C. You want to visit some well-known landmarks, find good places to eat and avoid large crowds. What time of year would be the best time to go, what landmarks can you visit, where should you have dinner? These are all questions that our data analysis of Wikipedia scraping and Foursquare data can use. \n",
    "\n",
    "\n",
    "### The stakeholders: in this case the stake holder is the Washington D.C city govornment. Tourism is a siginfigant industry in Washington D.C and it is important to understand where are the most popular landmarks, perhaps where new business could be set up. Maybe there are some national landmarks that are not that widely visited--and could be used to advertise \"little known\" Washington D.C landmarks. Armed with this new data knowledge, the city of Washington D.C can improve their tourist industry and identify where they should focus their efforts to improve the tourism experience. By improving the tourist industry, many businesses and people will see improve economic gains. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Data Description\n",
    "### This project gathering data from two major sources, Foursquare and Wikipedia. From Wikipedia we can scrape a list of Landmarks and places to visit in Washington D.C many of these pages also have latitude and longitude coordinates to use. \n",
    "### We then will gather from Foursquare what venues are also around the landmarks in D.C, since with my limited credentials I cannot get stats from those venues I am limited. However armed with the list of landmarks and nearby venues I should be able to perform some sort of clustering to figure out what are some of the best places to visit nearby. \n",
    "### After we have scrape the two data sets, we will then plot them in a map and perform some k-mean clustering on the businesses, and landmarks on them to find clusters of the data. Perhaps we can identify parititons of the national landmarks. \n",
    "### From that data we can identify types of businesses cluster around these landmarks and use those to gauge how popular a landmark is and what types of businesses are around them. For example, are there a lot of hotels in the area-- easy access for visitors. Maybe there are lots of restaurants, so maybe more money could be alloticated to sprucing up that landmark. The possibilities are endless, but by having a better understanding of these landmarks and nearby businesses the city of D.C can better alloticate resources to those more localized communties. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
